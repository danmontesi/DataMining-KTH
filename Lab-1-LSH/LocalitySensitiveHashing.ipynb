{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "sc = pyspark.SparkContext(\"local\", \"lhs\")\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/danmontesi/Desktop/Data-Mining-KTH\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the documents and import as string\n",
    "numberOfDocuments = 10\n",
    "documents = []\n",
    "for i in range(numberOfDocuments):\n",
    "    documents.append(sc.textFile(\"data/\"+str(i)+\".txt\"))\n",
    "    documents[i] = documents[i].map(lambda x: cleanDocument(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Remove basic punctuation and clean the document\n",
    "\"\"\"\n",
    "import string\n",
    "def cleanDocument(document):\n",
    "    document = document.lower()\n",
    "    document = document.translate(str.maketrans('','',string.punctuation))\n",
    "    return document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    " Create function Shingling that constructs k–shingles of a given length k (e.g., 10) from a given document, \n",
    " computes a hash value for each unique shingle, and represents the document in the form of an ordered set of \n",
    " its hashed k-shingles.\n",
    "\"\"\"\n",
    "\n",
    "def hashShingling(shingle, mod=2 ** 32 - 1):\n",
    "    \"\"\"\n",
    "    Given a shingle, returns its hashed value\n",
    "    the hash function is defined as below.\n",
    "    hash(char) = val*26 + getAscii(char)%mod\n",
    "\n",
    "    :param shingle: input characters sequence\n",
    "    :return val: hashed value for the string\n",
    "    \"\"\"\n",
    "\n",
    "    val = 0\n",
    "    for c in shingle:\n",
    "        val = (val * 26 + ord(c)) % mod\n",
    "    return val\n",
    "\n",
    "\n",
    "\n",
    "def get_shinglings(document, k):\n",
    "    \"\"\"\n",
    "    Get list of shinglings from a document as a list\n",
    "    :param document: Document in form of String\n",
    "    \"\"\"\n",
    "\n",
    "    shinglings = []\n",
    "    for i in range(k - 1, len(document)):\n",
    "        shinglings.append(hashShingling(document[i - k + 1:i]))\n",
    "\n",
    "    return np.array(shinglings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "Function MinHashing that builds a minHash signature (in the form of a vector or a set)\n",
    "of a given length n from a given set of integers (a set of hashed shingles).\n",
    "\"\"\"\n",
    "\n",
    "class VectorWrapper():\n",
    "    def __init__(self, vector):\n",
    "        self.vector = vector\n",
    "\n",
    "n = 1000\n",
    "coefficient = np.random.randint(2 ** 32 - 1, size=n)\n",
    "bias = np.random.randint(2 ** 32 - 1, size=n)\n",
    "mod = np.ones(n) * 2 ** 32 - 1\n",
    "\n",
    "def hashValue(value, signature):\n",
    "    return (value * coefficient[signature] + bias[signature]) % mod[signature]\n",
    "\n",
    "def hashVector(vector, signature):\n",
    "    return np.vectorize(hashValue)(vector, signature)\n",
    "\n",
    "def minHashVector(signature, vectorWrapper):\n",
    "    return np.amin(hashVector(vectorWrapper.vector, signature))\n",
    "\n",
    "def MinHashing(vector):\n",
    "    return np.vectorize(minHashVector)(np.arange(n), VectorWrapper(vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Class CompareSets:\n",
    "It computes the Jaccard similarity of two sets of integers – two sets of hashed shingles.\n",
    "\"\"\"\n",
    "\n",
    "def computeJaccard(set1, set2):\n",
    "    #To be sure that the user inputted a set:\n",
    "    a = set(set1)\n",
    "    b = set(set2)\n",
    "\n",
    "    union = a.union(b)\n",
    "    intersection = a.intersection(b)\n",
    "    print(\"Similarity between the 2 sets is \" + str(round(len(intersection)/len(union), 2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CompareSignatures: estimates similarity of two integer vectors – minhash signatures –\n",
    "as a fraction of components, in which they agree.\n",
    "\"\"\"\n",
    "\n",
    "def getSimilarity(list1, list2):\n",
    "    comparison = np.dstack((list1, list2))[0]\n",
    "    print(\"Similarity between the 2 vectors is \" + str(\n",
    "    len(list(filter(lambda x: x[0] == x[1], comparison))) / len(comparison)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Bonus task:\n",
    "Class LSH that implements the LSH technique: given a collection of minhash signatures\n",
    "(integer vectors) and a similarity threshold t, the LSH class (using banding and hashing)\n",
    "finds all candidate pairs of signatures that agree on at least fraction t of their components.\n",
    "\"\"\"\n",
    "\n",
    "signatures_lists = []\n",
    "bands_num = 25\n",
    "signatures = 100\n",
    "doc_num = numberOfDocuments\n",
    "\n",
    "def vectorHash(vector):\n",
    "    \"\"\"\n",
    "    Computes an hash value given a vector\n",
    "    :return: hashed value\n",
    "    \"\"\"\n",
    "    return np.sum(vector) % 2 ** 32 - 1\n",
    "\n",
    "def generateCandidates(vector):\n",
    "    \"\"\"\n",
    "    Given a vector, states whether it is a candidate or not\n",
    "    \"\"\"\n",
    "\n",
    "    candidates = []\n",
    "    for x in vector:\n",
    "        for y in vector:\n",
    "            if x[0] < y[0] and x[1] == y[1]:\n",
    "                candidates.append((x[0], y[0]))\n",
    "    return candidates\n",
    "\n",
    "def LSH(signatures_lists,\n",
    "        bands_num = 25,\n",
    "        signatures = 100,\n",
    "        doc_num = len(signatures_lists)):\n",
    "\n",
    "    # Computer threshold from given bands_num and signatures\n",
    "    t = (1 / bands_num) ** (bands_num / signatures)\n",
    "    print(\"Threshold is set to \" + str(t))\n",
    "\n",
    "    # Generate signatures of a given list of integers\n",
    "    min_hash_lists = signatures_lists.map(lambda x: (x[0], MinHashing(x[1])))\n",
    "\n",
    "    # Create a tuples having as elements (bandId, (documentId, hashOverTheBand))\n",
    "    bands0 = min_hash_lists.flatMap(lambda x: np.arange(bands_num))\n",
    "    bands1 = min_hash_lists.flatMap(lambda x: np.ones(bands_num, dtype=int) * x[0])\n",
    "    bands2 = min_hash_lists.flatMap(lambda x: np.array(np.split(x[1], bands_num)))\n",
    "    bands2Hashed = bands2.map(lambda x: vectorHash(x))\n",
    "    bands12Hashed = bands1.zip(bands2Hashed)\n",
    "    bands = bands0.zip(bands12Hashed)\n",
    "\n",
    "    bandsInGroup = bands.groupByKey()\n",
    "\n",
    "    candidates = bandsInGroup.flatMap(lambda x: generateCandidates(x[1])).map(\n",
    "        lambda x: (x[0] * len(doc_num) + x[1], x)).values().distinct()\n",
    "    print(\"Candidates are: \" + str(candidates.collect()) )\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold is set to 0.4472135954999579\n",
      "Candidates are: []\n"
     ]
    }
   ],
   "source": [
    "# Create class shinglings to convert document into shingles and then into number\n",
    "shinglingSize = 3\n",
    "\n",
    "data = []\n",
    "for d in range(numberOfDocuments):\n",
    "    document = \"\"\n",
    "    for s in documents[d].collect():\n",
    "        document = document + s\n",
    "    shinglings = []\n",
    "    for i in range(shinglingSize - 1, len(document)):\n",
    "        # get the hash of the shingling and append to the new vector of integers\n",
    "        shinglings.append(hashShingling(document[i - shinglingSize + 1:i]))\n",
    "    data.append(shinglings)\n",
    "\n",
    "data = np.array(data)\n",
    "\n",
    "# create RDD and create LSH class\n",
    "dataRDD = sc.parallelize(data)\n",
    "dataWithIndex = dataRDD.zipWithIndex().map(lambda x: (x[1], x[0]))\n",
    "\n",
    "LSH(dataWithIndex, 25, 100, numberOfDocuments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
