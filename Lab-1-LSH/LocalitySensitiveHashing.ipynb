{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "sc = pyspark.SparkContext(\"local\", \"lhs\")\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/strenuus/dev/Data-Mining-KTH/Lab-1-LSH\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the documents and import as string\n",
    "numberOfDocuments = 10\n",
    "documents = []\n",
    "for i in range(numberOfDocuments):\n",
    "    documents.append(sc.textFile(\"data/\"+str(i)+\".txt\"))\n",
    "    documents[i] = documents[i].map(lambda x: cleanDocument(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Remove basic punctuation and clean the document\n",
    "\"\"\"\n",
    "import string\n",
    "def cleanDocument(document):\n",
    "    document = document.lower()\n",
    "    document = document.translate(str.maketrans('','',string.punctuation))\n",
    "    return document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Given a shingle, returns its hashed value\n",
    "\"\"\"\n",
    "\n",
    "def hashShingling(shingle, mod=2 ** 32 - 1):\n",
    "    val = 0\n",
    "    for c in shingle:\n",
    "        val = (val * 26 + ord(c)) % mod\n",
    "    return val\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    Get list of shinglings from a document as a list\n",
    "\"\"\"\n",
    "def get_shinglings(document, k):\n",
    "    shinglings = []\n",
    "    for i in range(k - 1, len(document)):\n",
    "        shinglings.append(hashShingling(document[i - k + 1:i]))\n",
    "\n",
    "    return np.array(shinglings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class VectorWrapper():\n",
    "    def __init__(self, vector):\n",
    "        self.vector = vector\n",
    "\n",
    "\"\"\"\n",
    "    The class Hasher contains all the useful functions to build a minHash signature (in the form of a vector)\n",
    "    of a given length from a given set of integers (a set of hashed shingles).\n",
    "\"\"\"\n",
    "\n",
    "class Hasher():\n",
    "    def __init__(self, signatures):\n",
    "        self.signatures = signatures\n",
    "        self.coefficient = np.random.randint(2**32-1, size=self.signatures)\n",
    "        self.bias = np.random.randint(2**32-1, size=self.signatures)\n",
    "        self.mod = np.ones(self.signatures)*2**32-1#np.random.randint(10000, size=self.signatures)\n",
    "        \n",
    "    def hashValue(self, value, signature):\n",
    "        return (value*self.coefficient[signature]+self.bias[signature])%self.mod[signature]\n",
    "    \n",
    "    # Compute hash of each element of a vector (vectorizing operation)\n",
    "    def hashVector(self, vector, signature):\n",
    "        return np.vectorize(self.hashValue)(vector, signature)\n",
    "    \n",
    "    # gets minimum of the (hashed) values in the vector given\n",
    "    def minHashVector(self, signature, vectorWrapper):\n",
    "        return np.amin(self.hashVector(vectorWrapper.vector, signature))\n",
    "    \n",
    "    # given a vector, returns the min-hash for all possible elements. \n",
    "    def generateSignatures(self, vector):\n",
    "        return np.vectorize(self.minHashVector)(np.arange(self.signatures), VectorWrapper(vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    It computes the Jaccard similarity of two sets of integers – two sets of hashed shingles.\n",
    "\"\"\"\n",
    "def computeJaccard(set1, set2):\n",
    "    #To be sure that the user inputted a set:\n",
    "    a = set(set1)\n",
    "    b = set(set2)\n",
    "\n",
    "    union = a.union(b)\n",
    "    intersection = a.intersection(b)\n",
    "    return round(len(intersection)/len(union), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "signatures = 100\n",
    "doc_num = numberOfDocuments\n",
    "hasher = Hasher(signatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Estimates similarity of two integer vectors – minhash signatures –\n",
    "    as a fraction of components, in which they agree.\n",
    "\"\"\"\n",
    "def getSimilarity(list1, list2):\n",
    "    comparison = np.dstack((list1, list2))[0]\n",
    "    return len(list(filter(lambda x: x[0] == x[1], comparison))) / len(comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Given a list of pairs of documents, it prints the min hashing similarities between these pairs.\n",
    "\"\"\"\n",
    "def print_min_hashing_similarities(min_hash_lists, candidates):\n",
    "    for couple in candidates:\n",
    "        first = min_hash_lists.filter(lambda x: x[0]==couple[0]).collect()[0][1]\n",
    "        second = min_hash_lists.filter(lambda x: x[0]==couple[1]).collect()[0][1]\n",
    "        print(\"Similarity between \"+str(couple[0])+\" and \"+str(couple[1])+\" is \"+str(getSimilarity(first, second)))\n",
    "\n",
    "\"\"\"\n",
    "    Generates the list of signatures for each document.\n",
    "\"\"\"\n",
    "def min_hashing(signature_lists, hasher):\n",
    "    min_hash_lists = signature_lists.map(lambda x: (x[0], hasher.generateSignatures(x[1])))\n",
    "    return min_hash_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Computes an hash value given a vector. \n",
    "\"\"\"\n",
    "def vectorHash(vector):\n",
    "    return np.sum(vector) % (2 ** 32 - 1)\n",
    "\n",
    "\"\"\"\n",
    "    Given a bucket, generate all the possible pairs of candidates for that bucket. \n",
    "\"\"\"\n",
    "def generateCandidates(vector):\n",
    "    candidates = []\n",
    "    for x in vector:\n",
    "        for y in vector:\n",
    "            if x[0] < y[0] and x[1] == y[1]:\n",
    "                candidates.append((x[0], y[0]))\n",
    "    return candidates\n",
    "\n",
    "\"\"\"\n",
    "    Given a collection of minhash signatures (integer vectors) and a similarity threshold t, the functions (using banding and hashing)\n",
    "    finds all candidate pairs of signatures that agree on at least fraction t of their components and print their similarities.\n",
    "\"\"\"\n",
    "def lsh_test(doc_num, min_hash_lists):\n",
    "    \n",
    "    # Computes threshold from given bands_num and signatures\n",
    "    def getThreshold(signatures, bands_num):\n",
    "        return np.round((1 / bands_num) ** (bands_num / signatures),4)\n",
    "        \n",
    "    possible_bands = []\n",
    "    for i in range(1, signatures//2 +1):\n",
    "        if signatures%i == 0:\n",
    "            possible_bands.append(i)\n",
    "            \n",
    "    for i in range(len(possible_bands)):\n",
    "        print(\"{}: {}\".format(i, getThreshold(signatures, possible_bands[i])))\n",
    "    choice = int(input(\"Which threshold would you like to select? Please insert the index id:\") )\n",
    "    # TODO catch errors\n",
    "    \n",
    "    bands_num = possible_bands[choice]\n",
    "   \n",
    "    print(\"Threshold is set to \" + str(getThreshold(signatures, bands_num)))\n",
    "\n",
    "    # Create a tuples having as elements (bandId, (documentId, hashOverTheBand))\n",
    "    \n",
    "    # [1,2,3,4,5.... num_bands]\n",
    "    bands0 = min_hash_lists.flatMap(lambda x: np.arange(bands_num))\n",
    "    # [1,1, ..... 1] , len = num_bands\n",
    "    bands1 = min_hash_lists.flatMap(lambda x: np.ones(bands_num, dtype=int) * x[0])\n",
    "    # split in num_bands same length parts the dataset\n",
    "    bands2 = min_hash_lists.flatMap(lambda x: np.array(np.split(x[1], bands_num)))\n",
    "    \n",
    "    # get hash of vectors created (bands)\n",
    "    bands2Hashed = bands2.map(lambda x: vectorHash(x))\n",
    "    \n",
    "    # create couples (1, hashed_vector1), (1, hashed_vector2), ...\n",
    "    bands12Hashed = bands1.zip(bands2Hashed)\n",
    "    \n",
    "    # create couples (1,(1, hashed_vector1)), (2,(1, hashed_vector2)), ...\n",
    "    bands = bands0.zip(bands12Hashed)\n",
    "\n",
    "    # for each bend, I have all possible buck\n",
    "    bandsInGroup = bands.groupByKey()\n",
    "\n",
    "    candidates = bandsInGroup.flatMap(lambda x: generateCandidates(x[1])).map(\n",
    "        lambda x: (x[0] * doc_num + x[1], x)).values().distinct()\n",
    "    print(\"Candidates are: \" + str(candidates.collect()) )\n",
    "    \n",
    "    print_min_hashing_similarities(min_hash_lists, candidates.collect())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Compute the jaccard similarities between all the documents\n",
    "\"\"\"\n",
    "def jaccard_test():\n",
    "    for i in range(len(data)):\n",
    "        for j in range(i+1, len(data)):\n",
    "            print(\"Jaccard similarity between document {} and {} is {}\".format(i, j, computeJaccard(data[i], data[j])))\n",
    "    \n",
    "\"\"\"\n",
    "    Computes the approximate Jaccard similarities with min hashing between all the documents \n",
    "\"\"\"\n",
    "def min_hashing_test(signatures_lists, min_hash_lists):\n",
    "    \n",
    "    candidates = []\n",
    "    for i in range(len(data)):\n",
    "        for j in range(i+1, len(data)):\n",
    "            candidates.append((i, j))\n",
    "    \n",
    "    print_min_hashing_similarities(min_hash_lists, candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create class shinglings to convert document into shingles and then into number\n",
    "shinglingSize = 7\n",
    "\n",
    "# Create function Shingling that constructs k–shingles of a given length shinglingSize, from each document, \n",
    "# computes a hash value for each unique shingle, and represents the document in the form of an ordered set of \n",
    "# its hashed shinglingSize-shingles.\n",
    "\n",
    "data = []\n",
    "for d in range(numberOfDocuments):\n",
    "    document = \"\"\n",
    "    for s in documents[d].collect():\n",
    "        document = document + s\n",
    "    shinglings = []\n",
    "    for i in range(shinglingSize - 1, len(document)):\n",
    "        # get the hash of the shingling and append to the new vector of integers\n",
    "        shinglings.append(hashShingling(document[i - shinglingSize + 1:i]))\n",
    "    data.append(shinglings)\n",
    "\n",
    "data = np.array(data)\n",
    "\n",
    "# create RDD and create LSH class\n",
    "dataRDD = sc.parallelize(data)\n",
    "dataWithIndex = dataRDD.zipWithIndex().map(lambda x: (x[1], x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard similarity between document 0 and 1 is 0.05\n",
      "Jaccard similarity between document 0 and 2 is 0.05\n",
      "Jaccard similarity between document 0 and 3 is 0.05\n",
      "Jaccard similarity between document 0 and 4 is 0.03\n",
      "Jaccard similarity between document 0 and 5 is 0.02\n",
      "Jaccard similarity between document 0 and 6 is 0.02\n",
      "Jaccard similarity between document 0 and 7 is 0.03\n",
      "Jaccard similarity between document 0 and 8 is 0.01\n",
      "Jaccard similarity between document 0 and 9 is 0.01\n",
      "Jaccard similarity between document 1 and 2 is 0.06\n",
      "Jaccard similarity between document 1 and 3 is 0.04\n",
      "Jaccard similarity between document 1 and 4 is 0.05\n",
      "Jaccard similarity between document 1 and 5 is 0.03\n",
      "Jaccard similarity between document 1 and 6 is 0.03\n",
      "Jaccard similarity between document 1 and 7 is 0.02\n",
      "Jaccard similarity between document 1 and 8 is 0.01\n",
      "Jaccard similarity between document 1 and 9 is 0.01\n",
      "Jaccard similarity between document 2 and 3 is 0.04\n",
      "Jaccard similarity between document 2 and 4 is 0.03\n",
      "Jaccard similarity between document 2 and 5 is 0.02\n",
      "Jaccard similarity between document 2 and 6 is 0.04\n",
      "Jaccard similarity between document 2 and 7 is 0.03\n",
      "Jaccard similarity between document 2 and 8 is 0.03\n",
      "Jaccard similarity between document 2 and 9 is 0.01\n",
      "Jaccard similarity between document 3 and 4 is 0.05\n",
      "Jaccard similarity between document 3 and 5 is 0.04\n",
      "Jaccard similarity between document 3 and 6 is 0.04\n",
      "Jaccard similarity between document 3 and 7 is 0.03\n",
      "Jaccard similarity between document 3 and 8 is 0.02\n",
      "Jaccard similarity between document 3 and 9 is 0.01\n",
      "Jaccard similarity between document 4 and 5 is 0.31\n",
      "Jaccard similarity between document 4 and 6 is 0.04\n",
      "Jaccard similarity between document 4 and 7 is 0.04\n",
      "Jaccard similarity between document 4 and 8 is 0.03\n",
      "Jaccard similarity between document 4 and 9 is 0.01\n",
      "Jaccard similarity between document 5 and 6 is 0.02\n",
      "Jaccard similarity between document 5 and 7 is 0.02\n",
      "Jaccard similarity between document 5 and 8 is 0.03\n",
      "Jaccard similarity between document 5 and 9 is 0.02\n",
      "Jaccard similarity between document 6 and 7 is 0.05\n",
      "Jaccard similarity between document 6 and 8 is 0.03\n",
      "Jaccard similarity between document 6 and 9 is 0.02\n",
      "Jaccard similarity between document 7 and 8 is 0.04\n",
      "Jaccard similarity between document 7 and 9 is 0.03\n",
      "Jaccard similarity between document 8 and 9 is 0.52\n"
     ]
    }
   ],
   "source": [
    "# compute the jaccard similarities between all the documents\n",
    "jaccard_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieves the list of signatures for each document.\n",
    "min_hash_lists = min_hashing(dataWithIndex, hasher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between 0 and 1 is 0.02\n",
      "Similarity between 0 and 2 is 0.07\n",
      "Similarity between 0 and 3 is 0.06\n",
      "Similarity between 0 and 4 is 0.02\n",
      "Similarity between 0 and 5 is 0.01\n",
      "Similarity between 0 and 6 is 0.01\n",
      "Similarity between 0 and 7 is 0.07\n",
      "Similarity between 0 and 8 is 0.02\n",
      "Similarity between 0 and 9 is 0.01\n",
      "Similarity between 1 and 2 is 0.06\n",
      "Similarity between 1 and 3 is 0.03\n",
      "Similarity between 1 and 4 is 0.02\n",
      "Similarity between 1 and 5 is 0.02\n",
      "Similarity between 1 and 6 is 0.06\n",
      "Similarity between 1 and 7 is 0.02\n",
      "Similarity between 1 and 8 is 0.01\n",
      "Similarity between 1 and 9 is 0.01\n",
      "Similarity between 2 and 3 is 0.04\n",
      "Similarity between 2 and 4 is 0.03\n",
      "Similarity between 2 and 5 is 0.01\n",
      "Similarity between 2 and 6 is 0.03\n",
      "Similarity between 2 and 7 is 0.02\n",
      "Similarity between 2 and 8 is 0.05\n",
      "Similarity between 2 and 9 is 0.02\n",
      "Similarity between 3 and 4 is 0.04\n",
      "Similarity between 3 and 5 is 0.05\n",
      "Similarity between 3 and 6 is 0.04\n",
      "Similarity between 3 and 7 is 0.03\n",
      "Similarity between 3 and 8 is 0.03\n",
      "Similarity between 3 and 9 is 0.01\n",
      "Similarity between 4 and 5 is 0.34\n",
      "Similarity between 4 and 6 is 0.02\n",
      "Similarity between 4 and 7 is 0.01\n",
      "Similarity between 4 and 8 is 0.05\n",
      "Similarity between 4 and 9 is 0.02\n",
      "Similarity between 5 and 6 is 0.02\n",
      "Similarity between 5 and 7 is 0.0\n",
      "Similarity between 5 and 8 is 0.02\n",
      "Similarity between 5 and 9 is 0.02\n",
      "Similarity between 6 and 7 is 0.03\n",
      "Similarity between 6 and 8 is 0.03\n",
      "Similarity between 6 and 9 is 0.02\n",
      "Similarity between 7 and 8 is 0.05\n",
      "Similarity between 7 and 9 is 0.06\n",
      "Similarity between 8 and 9 is 0.5\n"
     ]
    }
   ],
   "source": [
    "# computes the approximate Jaccard similarities with min hashing between all the documents\n",
    "min_hashing_test(dataWithIndex, min_hash_lists )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 1.0\n",
      "1: 0.9862\n",
      "2: 0.9461\n",
      "3: 0.9227\n",
      "4: 0.7943\n",
      "5: 0.5493\n",
      "6: 0.4472\n",
      "7: 0.1414\n",
      "Which threshold would you like to select? Please insert their index id:5\n",
      "Threshold is set to 0.5493\n",
      "Candidates are: [(8, 9)]\n",
      "Similarity between 8 and 9 is 0.58\n"
     ]
    }
   ],
   "source": [
    "# computes the approximate Jaccard similarities with min hashing between all the pairs of documents that are likely to have a similarity higher than the chosen treshold\n",
    "lsh_test(numberOfDocuments, min_hash_lists )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
