{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "sc = pyspark.SparkContext(\"local\", \"lhs\")\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/danmontesi/Desktop/Data-Mining-KTH/Lab-1-LSH\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the documents and import as string\n",
    "numberOfDocuments = 10\n",
    "documents = []\n",
    "for i in range(numberOfDocuments):\n",
    "    documents.append(sc.textFile(\"data/\"+str(i)+\".txt\"))\n",
    "    documents[i] = documents[i].map(lambda x: cleanDocument(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Remove basic punctuation and clean the document\n",
    "\"\"\"\n",
    "import string\n",
    "def cleanDocument(document):\n",
    "    document = document.lower()\n",
    "    document = document.translate(str.maketrans('','',string.punctuation))\n",
    "    return document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    " Create function Shingling that constructs k–shingles of a given length k (e.g., 10) from a given document, \n",
    " computes a hash value for each unique shingle, and represents the document in the form of an ordered set of \n",
    " its hashed k-shingles.\n",
    "\"\"\"\n",
    "\n",
    "def hashShingling(shingle, mod=2 ** 32 - 1):\n",
    "    \"\"\"\n",
    "    Given a shingle, returns its hashed value\n",
    "    the hash function is defined as below.\n",
    "    hash(char) = val*26 + getAscii(char)%mod\n",
    "\n",
    "    :param shingle: input characters sequence\n",
    "    :return val: hashed value for the string\n",
    "    \"\"\"\n",
    "\n",
    "    val = 0\n",
    "    for c in shingle:\n",
    "        val = (val * 26 + ord(c)) % mod\n",
    "    return val\n",
    "\n",
    "\n",
    "\n",
    "def get_shinglings(document, k):\n",
    "    \"\"\"\n",
    "    Get list of shinglings from a document as a list\n",
    "    :param document: Document in form of String\n",
    "    \"\"\"\n",
    "\n",
    "    shinglings = []\n",
    "    for i in range(k - 1, len(document)):\n",
    "        shinglings.append(hashShingling(document[i - k + 1:i]))\n",
    "\n",
    "    return np.array(shinglings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "Function MinHashing that builds a minHash signature (in the form of a vector or a set)\n",
    "of a given length n from a given set of integers (a set of hashed shingles).\n",
    "\"\"\"\n",
    "\n",
    "class VectorWrapper():\n",
    "    def __init__(self, vector):\n",
    "        self.vector = vector\n",
    "\n",
    "class Hasher():\n",
    "    def __init__(self, signatures):\n",
    "        self.signatures = signatures\n",
    "        self.coefficient = np.random.randint(2**32-1, size=self.signatures)\n",
    "        self.bias = np.random.randint(2**32-1, size=self.signatures)\n",
    "        self.mod = np.ones(self.signatures)*2**32-1#np.random.randint(10000, size=self.signatures)\n",
    "        \n",
    "    def hashValue(self, value, signature):\n",
    "        return (value*self.coefficient[signature]+self.bias[signature])%self.mod[signature]\n",
    "    \n",
    "    def hashVector(self, vector, signature):\n",
    "        return np.vectorize(self.hashValue)(vector, signature)\n",
    "    \n",
    "    def minHashVector(self, signature, vectorWrapper):\n",
    "        return np.amin(self.hashVector(vectorWrapper.vector, signature))\n",
    "    \n",
    "    def generateSignatures(self, vector):\n",
    "        return np.vectorize(self.minHashVector)(np.arange(self.signatures), VectorWrapper(vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Class CompareSets:\n",
    "It computes the Jaccard similarity of two sets of integers – two sets of hashed shingles.\n",
    "\"\"\"\n",
    "\n",
    "def computeJaccard(set1, set2):\n",
    "    #To be sure that the user inputted a set:\n",
    "    a = set(set1)\n",
    "    b = set(set2)\n",
    "\n",
    "    union = a.union(b)\n",
    "    intersection = a.intersection(b)\n",
    "    return round(len(intersection)/len(union), 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CompareSignatures: estimates similarity of two integer vectors – minhash signatures –\n",
    "as a fraction of components, in which they agree.\n",
    "\"\"\"\n",
    "\n",
    "def getSimilarity(list1, list2):\n",
    "    comparison = np.dstack((list1, list2))[0]\n",
    "    return len(list(filter(lambda x: x[0] == x[1], comparison))) / len(comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Bonus task:\n",
    "Class LSH that implements the LSH technique: given a collection of minhash signatures\n",
    "(integer vectors) and a similarity threshold t, the LSH class (using banding and hashing)\n",
    "finds all candidate pairs of signatures that agree on at least fraction t of their components.\n",
    "\"\"\"\n",
    "\n",
    "bands_num = 25\n",
    "signatures = 100\n",
    "doc_num = numberOfDocuments\n",
    "hasher = Hasher(signatures)\n",
    "\n",
    "def vectorHash(vector):\n",
    "    \"\"\"\n",
    "    Computes an hash value given a vector\n",
    "    :return: hashed value  \"\"\"\n",
    "    return np.sum(vector) % (2 ** 32 - 1)\n",
    "\n",
    "def generateCandidates(vector):\n",
    "    \"\"\"\n",
    "    Given a vector, states whether it is a candidate or not\n",
    "    \"\"\"\n",
    "    candidates = []\n",
    "    for x in vector:\n",
    "        for y in vector:\n",
    "            if x[0] < y[0] and x[1] == y[1]:\n",
    "                candidates.append((x[0], y[0]))\n",
    "    return candidates\n",
    "\n",
    "\"\"\"\n",
    "    ....\n",
    "\"\"\"\n",
    "def min_hashing(signature_lists, hasher):\n",
    "    min_hash_lists = signature_lists.map(lambda x: (x[0], hasher.generateSignatures(x[1])))\n",
    "    return min_hash_lists\n",
    "\n",
    "\n",
    "def LSH(signatures_lists, signatures = 100, doc_num = 10):\n",
    "    \n",
    "    # Computer threshold from given bands_num and signatures\n",
    "    def getThreshold(signatures, bands_num):\n",
    "        return np.round((1 / bands_num) ** (bands_num / signatures),4)\n",
    "        \n",
    "    possible_bands = []\n",
    "    for i in range(1, signatures//2 +1):\n",
    "        if signatures%i == 0:\n",
    "            possible_bands.append(i)\n",
    "            \n",
    "    for i in range(len(possible_bands)):\n",
    "        print(\"{}: {}\".format(i, getThreshold(signatures, possible_bands[i])))\n",
    "    choice = int(input(\"Which threshold would you like to select? Please insert their index id:\") )\n",
    "    # TODO catch errors\n",
    "    \n",
    "    bands_num = possible_bands[choice]\n",
    "   \n",
    "    print(\"Threshold is set to \" + str(getThreshold(signatures, bands_num)))\n",
    "    # Generate signatures of a given list of integers\n",
    "    \n",
    "    min_hash_lists = min_hashing(signatures_lists, hasher)\n",
    "\n",
    "    # Create a tuples having as elements (bandId, (documentId, hashOverTheBand))\n",
    "    bands0 = min_hash_lists.flatMap(lambda x: np.arange(bands_num))\n",
    "    bands1 = min_hash_lists.flatMap(lambda x: np.ones(bands_num, dtype=int) * x[0])\n",
    "    bands2 = min_hash_lists.flatMap(lambda x: np.array(np.split(x[1], bands_num)))\n",
    "    bands2Hashed = bands2.map(lambda x: vectorHash(x))\n",
    "    bands12Hashed = bands1.zip(bands2Hashed)\n",
    "    bands = bands0.zip(bands12Hashed)\n",
    "\n",
    "    bandsInGroup = bands.groupByKey()\n",
    "\n",
    "    candidates = bandsInGroup.flatMap(lambda x: generateCandidates(x[1])).map(\n",
    "        lambda x: (x[0] * doc_num + x[1], x)).values().distinct()\n",
    "    print(\"Candidates are: \" + str(candidates.collect()) )\n",
    "    \n",
    "    for couple in candidates.collect():\n",
    "        first = min_hash_lists.filter(lambda x: x[0]==couple[0]).collect()[0][1]\n",
    "        second = min_hash_lists.filter(lambda x: x[0]==couple[1]).collect()[0][1]\n",
    "        print(\"Similarity between \"+str(couple[0])+\" and \"+str(couple[1])+\" is \"+str(getSimilarity(first, second)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PythonRDD[52] at RDD at PythonRDD.scala:53\n",
      "0: 1.0\n",
      "1: 0.9862\n",
      "2: 0.9461\n",
      "3: 0.9227\n",
      "4: 0.7943\n",
      "5: 0.5493\n",
      "6: 0.4472\n",
      "7: 0.1414\n",
      "Which threshold would you like to select? Please insert their index id:6\n",
      "Threshold is set to 0.4472\n",
      "Candidates are: [(8, 9)]\n",
      "Similarity between 8 and 9 is 0.65\n"
     ]
    }
   ],
   "source": [
    "# Create class shinglings to convert document into shingles and then into number\n",
    "shinglingSize = 7\n",
    "\n",
    "data = []\n",
    "for d in range(numberOfDocuments):\n",
    "    document = \"\"\n",
    "    for s in documents[d].collect():\n",
    "        document = document + s\n",
    "    shinglings = []\n",
    "    for i in range(shinglingSize - 1, len(document)):\n",
    "        # get the hash of the shingling and append to the new vector of integers\n",
    "        shinglings.append(hashShingling(document[i - shinglingSize + 1:i]))\n",
    "    data.append(shinglings)\n",
    "\n",
    "data = np.array(data)\n",
    "\n",
    "# create RDD and create LSH class\n",
    "dataRDD = sc.parallelize(data)\n",
    "dataWithIndex = dataRDD.zipWithIndex().map(lambda x: (x[1], x[0]))\n",
    "\n",
    "LSH(dataWithIndex, 100, numberOfDocuments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 funzioni\n",
    "\n",
    "# data = [ [3214, 31431, 134134, ...], [...]]\n",
    "\n",
    "\"\"\"\n",
    "    Computes the Jaccard Similarity for each document\n",
    "    documents are already split in hash shingles and saved \n",
    "    global vsriable data\n",
    "\"\"\"\n",
    "def jaccard_test():\n",
    "    for i in range(len(data)):\n",
    "        for j in range(i+1, len(data)):\n",
    "            print(\"Jaccard similarity between document {} and {} is {}\".format(i, j, computeJaccard(data[i], data[j])))\n",
    "    \n",
    "\"\"\"\n",
    "    Computes the MinHashing Similarity for each document\n",
    "    global vsriable ...\n",
    "    signatures_lists = datawithindex...\n",
    "    \n",
    "\"\"\"\n",
    "def min_hashing_test(signatures_lists, min_hash_lists):\n",
    "    \n",
    "    for couple in signatures_lists.collect():\n",
    "        first = min_hash_lists.filter(lambda x: x[0]==couple[0]).collect()[0]\n",
    "        second = min_hash_lists.filter(lambda x: x[0]==couple[1]).collect()[0]\n",
    "        print(\"Similarity between \"+str(couple[0])+\" and \"+str(couple[1])+\" is \"+str(getSimilarity(first, second)))\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "# min-hashing senza lsh con i 10 documenti\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard similarity between document 0 and 1 is 0.03\n",
      "Jaccard similarity between document 0 and 2 is 0.03\n",
      "Jaccard similarity between document 0 and 3 is 0.02\n",
      "Jaccard similarity between document 0 and 4 is 0.01\n",
      "Jaccard similarity between document 0 and 5 is 0.0\n",
      "Jaccard similarity between document 0 and 6 is 0.0\n",
      "Jaccard similarity between document 0 and 7 is 0.0\n",
      "Jaccard similarity between document 0 and 8 is 0.0\n",
      "Jaccard similarity between document 0 and 9 is 0.0\n",
      "Jaccard similarity between document 1 and 2 is 0.03\n",
      "Jaccard similarity between document 1 and 3 is 0.02\n",
      "Jaccard similarity between document 1 and 4 is 0.03\n",
      "Jaccard similarity between document 1 and 5 is 0.01\n",
      "Jaccard similarity between document 1 and 6 is 0.01\n",
      "Jaccard similarity between document 1 and 7 is 0.0\n",
      "Jaccard similarity between document 1 and 8 is 0.0\n",
      "Jaccard similarity between document 1 and 9 is 0.0\n",
      "Jaccard similarity between document 2 and 3 is 0.01\n",
      "Jaccard similarity between document 2 and 4 is 0.01\n",
      "Jaccard similarity between document 2 and 5 is 0.0\n",
      "Jaccard similarity between document 2 and 6 is 0.01\n",
      "Jaccard similarity between document 2 and 7 is 0.01\n",
      "Jaccard similarity between document 2 and 8 is 0.01\n",
      "Jaccard similarity between document 2 and 9 is 0.0\n",
      "Jaccard similarity between document 3 and 4 is 0.02\n",
      "Jaccard similarity between document 3 and 5 is 0.02\n",
      "Jaccard similarity between document 3 and 6 is 0.01\n",
      "Jaccard similarity between document 3 and 7 is 0.01\n",
      "Jaccard similarity between document 3 and 8 is 0.0\n",
      "Jaccard similarity between document 3 and 9 is 0.0\n",
      "Jaccard similarity between document 4 and 5 is 0.26\n",
      "Jaccard similarity between document 4 and 6 is 0.01\n",
      "Jaccard similarity between document 4 and 7 is 0.01\n",
      "Jaccard similarity between document 4 and 8 is 0.01\n",
      "Jaccard similarity between document 4 and 9 is 0.0\n",
      "Jaccard similarity between document 5 and 6 is 0.01\n",
      "Jaccard similarity between document 5 and 7 is 0.0\n",
      "Jaccard similarity between document 5 and 8 is 0.01\n",
      "Jaccard similarity between document 5 and 9 is 0.0\n",
      "Jaccard similarity between document 6 and 7 is 0.02\n",
      "Jaccard similarity between document 6 and 8 is 0.01\n",
      "Jaccard similarity between document 6 and 9 is 0.01\n",
      "Jaccard similarity between document 7 and 8 is 0.01\n",
      "Jaccard similarity between document 7 and 9 is 0.02\n",
      "Jaccard similarity between document 8 and 9 is 0.51\n"
     ]
    }
   ],
   "source": [
    "jaccard_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-b240e89a046e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmin_hashing_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataWithIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_hashing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataWithIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhasher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-29-aef65b8c5f21>\u001b[0m in \u001b[0;36mmin_hashing_test\u001b[0;34m(signatures_lists, min_hash_lists)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcouple\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msignatures_lists\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mfirst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin_hash_lists\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mcouple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0msecond\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin_hash_lists\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mcouple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Similarity between \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcouple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\" and \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcouple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\" is \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetSimilarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msecond\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "min_hashing_test(dataWithIndex, min_hashing(dataWithIndex, hasher))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
