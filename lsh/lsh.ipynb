{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "sc = pyspark.SparkContext(\"local\", \"lhs\")\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([[1000,2000,3000,4000,5000,6000,7000,8000], [1000,2000,3000,4000,5000,6000,7000,8000], [1000,2000,3000,4000], [5000,6000,7000,8000]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataRDD = sc.parallelize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataWithIndex = dataRDD.zipWithIndex().map(lambda x: (x[1], x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorWrapper():\n",
    "    def __init__(self, vector):\n",
    "        self.vector = vector\n",
    "        \n",
    "class Hasher():\n",
    "    def __init__(self, signatures):\n",
    "        self.signatures = signatures\n",
    "        self.mod = np.random.randint(1000, size=self.signatures)\n",
    "        self.bias = np.random.randint(1000, size=self.signatures)\n",
    "        \n",
    "    def hashValue(self, value, signature):\n",
    "        return value%self.mod[signature]+self.bias[signature]\n",
    "    \n",
    "    def hashVector(self, vector, signature):\n",
    "        return np.vectorize(self.hashValue)(vector, signature)\n",
    "    \n",
    "    def minHashVector(self, signature, vectorWrapper):\n",
    "        return np.amin(self.hashVector(vectorWrapper.vector, signature))\n",
    "    \n",
    "    def generateSignatures(self, vector):\n",
    "        return np.vectorize(self.minHashVector)(np.arange(self.signatures), VectorWrapper(vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "signatures = 1000\n",
    "numberOfBands = 200\n",
    "t = (1/numberOfBands)**(numberOfBands/signatures)\n",
    "#print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "hasher = Hasher(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "minHash = dataWithIndex.map(lambda x: (x[0], hasher.generateSignatures(x[1])))\n",
    "#print(minHash.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to improve\n",
    "def simpleHash(vector):\n",
    "    return np.sum(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bands0 = minHash.flatMap(lambda x: np.arange(numberOfBands))\n",
    "bands1 = minHash.flatMap(lambda x: np.ones(numberOfBands, dtype=int)*x[0])\n",
    "bands2 = minHash.flatMap(lambda x: np.array(np.split(x[1], numberOfBands)))\n",
    "bands2Hashed = bands2.map(lambda x: simpleHash(x))\n",
    "bands12Hashed = bands1.zip(bands2Hashed)\n",
    "bands = bands0.zip(bands12Hashed)\n",
    "#print(bands.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateCandidates(vector):\n",
    "    candidates = []\n",
    "    for x in vector:\n",
    "        for y in vector:\n",
    "            if x[0] < y[0] and x[1] == y[1]:\n",
    "                candidates.append((x[0], y[0]))\n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "bandsInGroup = bands.groupByKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = bandsInGroup.flatMap(lambda x: generateCandidates(x[1])).map(lambda x: (x[0]*len(data)+x[1], x)).values().distinct()\n",
    "#print(candidates.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(bandsInGroup.map(lambda x : (x[0], list(x[1]))).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between 0 and 1 is 1.0\n",
      "Similarity between 0 and 3 is 0.602\n",
      "Similarity between 1 and 3 is 0.602\n",
      "Similarity between 0 and 2 is 0.428\n",
      "Similarity between 1 and 2 is 0.428\n"
     ]
    }
   ],
   "source": [
    "for couple in candidates.collect():\n",
    "    first = minHash.filter(lambda x: x[0]==couple[0]).collect()[0][1]\n",
    "    second = minHash.filter(lambda x: x[0]==couple[1]).collect()[0][1]\n",
    "    comparison = np.dstack((first, second))[0]\n",
    "    print(\"Similarity between \"+str(couple[0])+\" and \"+str(couple[1])+\" is \"+str(len(list(filter(lambda x: x[0] == x[1], comparison)))/len(comparison)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
